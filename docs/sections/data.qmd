# Data

-   Sources
-   Description
-   Wrangling/cleaning
-   Spotting mistakes and missing data (could be part of EDA too)
-   Listing anomalies and outliers (could be part of EDA too)

## Properties Dataset

The dataset is stored in CSV format, comprising real estate listings scraped from the ImmoScout24 platform. It features a variety of fields related to property details

Source - [ImmoScout24](https://www.immoscout24.ch/en)

### Raw dataset

Here is the raw dataset:

```{r 2, warning=FALSE}
properties <- read.csv(file.path(here(),"data/properties.csv"))
# show 1000 first rows of properties using reactable

# show 100 first row of cleaned dataset using reactable
reactable(head(properties, 500),
          bordered = TRUE,
          striped = TRUE,
          highlight = TRUE,
          defaultPageSize = 5,
          showPageSizeOptions = TRUE,
          showPagination = TRUE,
          showSortable = TRUE,
          )
```

The instances in the dataset represent individual property listings. Each row corresponds to a unique listing on ImmoScout24.

Here is the number of observations by canton:

```{r}
# Create a tibble with cantons and observations
observations_table <- tibble(
  Canton = c("Vaud", "Bern", "Lucerne", "Zurich", "Uri", "Schwyz",
             "Obwalden", "Nidwalden", "Glarus", "St. Gallen", "Grisons", 
             "Aargau", "Thurgau", "Ticino", "Valais", "Neuchatel", 
             "Geneva", "Jura", "Zug", "Fribourg", "Solothurn", 
             "Basel-Stadt", "Basel-Landschaft", "Schaffhausen", 
             "Appenzell-Ausser-Rhoden", "Appenzell-Inner-Rhoden", "Total"),
  Observations = c(3232, 1553, 376, 1191, 71, 93, 29, 51, 55, 757, 405,
                   1481, 553, 4230, 3601, 513, 629, 329, 69, 1242, 590, 
                   149, 705, 118, 102, 12, sum(c(3232, 1553, 376, 1191, 71, 93, 29, 51, 55, 757, 405,
                                               1481, 553, 4230, 3601, 513, 629, 329, 69, 1242, 590, 
                                               149, 705, 118, 102, 12)))
)

# Display the table using kable and kableExtra
observations_table %>%
  kbl(caption = "Number of Observations by Canton") %>%
  kable_styling(position = "center", bootstrap_options = c("striped", "bordered", "hover")) %>%
  add_header_above(c(" " = 1, "Observations" = 1)) # Adds headers spanning columns

```

We have 22136 observations in total, distributed across different cantons in Switzerland.

### Wrangling and Cleaning

The data cleaning process for our dataset involves several careful steps to prepare the data for accurate analysis and modeling. Initially, we identify and address problematic values in the `number_of_rooms` field, where non-numeric entries are detected and marked for further cleaning. The price field is then sanitized to remove any non-numeric characters, ensuring all data in this column represent valid numerical values.

-   We exclude properties priced under 20,000 CHF because such low prices are often due to data entry mistakes or listings that do not reflect real market values, which can distort our analysis.

Further cleaning includes standardizing addresses by stripping unwanted characters at the beginning, enhancing uniformity across this variable. We remove rows with any NA values to maintain a dataset with complete cases for analysis. For the `square_meters` field, we remove non-digit characters and convert the cleansed string to numeric values, discarding any remaining NA entries from this transformation.

-   We remove NA values from the `square_meters` column to ensure that all entries are complete and usable for accurate modeling and analysis. Incomplete data can lead to errors and unreliable results.

Categorical data in year_category is truncated for consistency and converted into a factor for potential use in modeling. In the `number_of_rooms` field, non-relevant text (like "rooms" or "room") is removed, and we discard erroneous data such as entries mistakenly including "m²" or room counts exceeding 100, which are likely due to data entry oversights. If the number of rooms exceeds 27, we divide the value by ten, assuming these were misreported due to decimal placement errors.

Lastly, we enhance the readability and standardization of the canton field by capitalizing each entry, which is important for categorical consistency across the dataset. These steps ensure the dataset’s integrity and readiness for analytical processes, focusing on maintaining a robust, clean, and usable data structure.

```{r, warning=FALSE}
# Identify values causing the issue
problematic_values <- properties$number_of_rooms[is.na(as.numeric(properties$number_of_rooms))]
# Replace non-numeric values with NA
#properties$number_of_rooms <- as.numeric(gsub("[^0-9.]", "", properties$number_of_rooms))

# Remove non-numeric characters and convert to numeric
properties$price <- as.numeric(gsub("[^0-9]", "", properties$price))

# Subset the dataset to exclude rows with price < 20000
properties <- properties[properties$price >= 20000, ]

# Subset the dataset to exclude rows with numbers of rooms < 25
#properties <- properties[properties$number_of_rooms <25, ]

# Replace incomplete addresses
properties$address <- gsub("^\\W*[.,0-]\\W*", "", properties$address)

properties_filtered <- na.omit(properties)

properties_filtered$year_category <- substr(properties_filtered$year_category, 1, 9)
# Assuming 'year_category' is a column in the 'properties' dataset
properties_filtered$year_category <- as.factor(properties_filtered$year_category)


# remove m^2 from column 'square_meters'
properties_filtered$square_meters <- as.numeric(gsub("\\D", "", properties_filtered$square_meters))
# print how many NA observations left in square_meters
print(sum(is.na(properties_filtered$square_meters)))
# remove NA
properties_filtered <- properties_filtered[!is.na(properties_filtered$square_meters),]
# add majuscule to canton
properties_filtered$canton <- tools::toTitleCase(properties_filtered$canton)

# # Preprocess the number_of_rooms column
properties_filtered$number_of_rooms <- gsub(" rooms", "", properties_filtered$number_of_rooms)
properties_filtered$number_of_rooms <- gsub(" room", "", properties_filtered$number_of_rooms)
# Remove rows with "m²" in the "number_of_rooms" column
properties_filtered <- properties_filtered[!grepl("m²", properties_filtered$number_of_rooms), ]
properties_filtered$number_of_rooms <- as.numeric(properties_filtered$number_of_rooms)
# Remove rows with rooms >= 100
properties_filtered <- properties_filtered[properties_filtered$number_of_rooms <= 100, , drop = FALSE]
# Divide cells by 10 if number of rooms is more than 27
properties_filtered$number_of_rooms <- ifelse(properties_filtered$number_of_rooms > 27,
                                               properties_filtered$number_of_rooms / 10,
                                               properties_filtered$number_of_rooms)

#remove row with weird number of rooms
properties_filtered <- properties_filtered[properties_filtered$number_of_rooms != 7.6, ]



# properties_filtered$number_of_rooms <- as.character(properties_filtered$number_of_rooms)
# properties_filtered$number_of_rooms <- gsub("\\D", properties_filtered$number_of_rooms)  # Remove non-numeric characters
# properties_filtered$number_of_rooms <- as.numeric(properties_filtered$number_of_rooms)       # Convert to numeric
# properties_filtered$number_of_rooms <- trunc(properties_filtered$number_of_rooms)             # Truncate non-integer values
```

Here is the cleaned dataset:

```{r}
# show 100 first row of cleaned dataset using reactable
reactable(head(properties_filtered, 500),
          bordered = TRUE,
          striped = TRUE,
          highlight = TRUE,
          defaultPageSize = 5,
          showPageSizeOptions = TRUE,
          showPagination = TRUE,
          showSortable = TRUE,
          )
```

Here is a summary of the cleaned dataset:

```{r}
# Filter properties_filtered to contain only 'price', 'number_of_rooms', 'square_meters'
properties_summary <- properties_filtered[, c('price', 'number_of_rooms', 'square_meters')]

# Summary statistics
summary(properties_summary)

# Data
# Custom summary statistics with provided values
summary_stats <- data.frame(
  Min = c(format(25000, big.mark = "'"), format(1.00, big.mark = "'"), format(1, big.mark = "'")),
  Q1 = c(format(690000, big.mark = "'"), format(3.50, big.mark = "'"), format(99, big.mark = "'")),
  Median = c(format(992340, big.mark = "'"), format(4.50, big.mark = "'"), format(136, big.mark = "'")),
  Mean = c(format(1350852, big.mark = "'"), format(4.98, big.mark = "'"), format(160, big.mark = "'")),
  Q3 = c(format(1550000, big.mark = "'"), format(5.50, big.mark = "'"), format(190, big.mark = "'")),
  Max = c(format(26149500, big.mark = "'"), format(27.00, big.mark = "'"), format(2000, big.mark = "'"))
)

# Assign row names
row.names(summary_stats) <- c("price", "number_of_rooms", "square_meters")

# Create table
table <- kbl(summary_stats, align = rep('c', 6), caption = "Summary statistics for the dataset") %>%
  kable_styling(position = "center", bootstrap_options = c("striped", "hover", "condensed", "responsive"))

table
```

## AMTOVZ_CSV_LV95 Data

The "Official Index of Localities" (Répertoire officiel des localités) is provided by the Swiss Federal Office of Topography (swisstopo). This dataset includes detailed information about all localities in Switzerland and Liechtenstein, such as names, postal codes, and boundaries.

Updated monthly with input from cantonal authorities and Swiss Post, this data set is useful for spatial analysis, integration with other geographic data sets, and use in GIS and CAD systems. It's also valuable for statistical analysis and as a reference for information systems.

Periodic updates and release notes detail the changes and improvements made. Swisstopo manages and distributes this data set, fulfilling its role in providing official geospatial data for Switzerland.

Source - [swisstopo](https://www.swisstopo.admin.ch/fr/repertoire-officiel-des-localites)

### Wrangling and Cleaning

#### Creating Variable zip_code and merging with AMTOVZ_CSV_LV95

Here we create a new variable `zip_code` by extracting the zip code from the `address` column in the `properties_filtered` data set. We identify the zip code as a 4-digit number within the address and remove any leading digits if the zip code exceeds 4 digits. We then merge the `zip_code` variable with the `AMTOVZ_CSV_LV95` data set to obtain the corresponding city and canton information for each zip code.

```{r}
df <- properties_filtered
#the address column is like : '1844 Villeneuve VD' and has zip code number in it
#taking out the zip code number and creating a new column 'zip_code'
#the way to identify the zip code is to identify numbers that are 4 digits long
df$zip_code <- as.numeric(gsub("\\D", "", df$address))
#removing the first two number of zip code has more than 4 number
df$zip_code <- ifelse(df$zip_code > 9999, df$zip_code %% 10000, df$zip_code)
```

#### Using AMTOVZ_CSV_LV95 to get the city and canton from the zip code

Next, we used the AMTOVZ_CSV_LV95 data set to retrieve additional information such as the city and canton based on the extracted zip codes. This involved the following steps:

```{r zip}
#read .csv AMTOVZ_CSV_LV95
amto <- read.csv(file.path(here(),"data/AMTOVZ_CSV_WGS84.csv"), sep = ";")
#creating a new dataframe with 'Ortschaftsname' as 'City'Place_name', 'PLZ' as 'zip_code', 'KantonskÃ.rzel' as 'Canton_code', 'E' as 'lon' and 'N' as 'lat'
amto_df <- amto[, c('Gemeindename', 'PLZ', 'Kantonskürzel', 'E', 'N')]
#renaming the columns
colnames(amto_df) <- c('Community', 'zip_code', 'Canton_code', 'lon', 'lat')

#remove duplicates of zip code
amto_df <- amto_df[!duplicated(amto_df$zip_code),]

#add the variable of amto_df to the df if the zip code matches
df <- merge(df, amto_df, by = "zip_code", all.x = TRUE)

#check if there are nan in city
df[is.na(df$Community),]
```

Upon merging, we identified 77 rows where the Community was NA. This could happen for two reasons:

-   The zip code extracted from the address did not exist in the amto_df data set.
-   The zip code was incorrectly isolated from the address.

To ensure the integrity of our data, we decided to remove these rows with missing Community values:

```{r}
#remove the rows with nan in city
properties_filtered <- df[!is.na(df$Community),]
reactable(head(properties_filtered, 100),
          bordered = TRUE,
          striped = TRUE,
          highlight = TRUE,
          defaultPageSize = 5,
          showPageSizeOptions = TRUE,
          showPagination = TRUE,
          showSortable = TRUE,
          )
```

## Tax data

The Swiss Tax dataset encompasses comprehensive information on income, wealth, profits, and capital taxes for each canton and commune in Switzerland. It provides detailed data on tax rates and regulations, allowing for in-depth analysis and comparison across regions.

This dataset is sourced from various official authorities, including cantonal tax authorities and the Swiss Federal Tax Administration. It is regularly updated to reflect changes in tax laws, rates, and administrative details at both the cantonal and communal levels. This dataset might be useful to see if we have a link between some taxes and the prices of the properties

Updates and revisions to the dataset are provided periodically, ensuring its accuracy and relevance. The Swiss Federal Tax Administration oversees the distribution and management of this dataset, supporting its role in providing reliable and comprehensive tax information for Switzerland.

The dataset can be found here, take the year 2024 and the corresponding taxes.

Source - [swisstaxcalculator](https://swisstaxcalculator.estv.admin.ch/#/taxdata/tax-rates)

### Wrangling and Cleaning

```{r impots, warning=FALSE}
# read csv
impots <- read.csv(file.path(here(),"data/estv_income_rates.csv"), sep = ",", header = TRUE, stringsAsFactors = FALSE)

# Remove 1st row
impots <- impots[-1, ]
# Remove 3rd column
impots <- impots[, -3]

# Combine text for columns 4-8
impots[1, 4:8] <- "Impôt sur le revenu"
# Combine text for columns 9-13
impots[1, 9:13] <- "Impôt sur la fortune"
# Combine text for columns 14-16
impots[1, 14:16] <- "Impôt sur le bénéfice"
# Combine text for columns 17-19
impots[1, 17:19] <- "Impôt sur le capital"

# Combine content of the first 2 rows into the 2nd row
impots[2, ] <- apply(impots[1:2, ], 2, function(x) paste(ifelse(is.na(x[1]), x[2], ifelse(is.na(x[2]), x[1], paste(x[1], x[2], sep = " ")))))

# Remove 1st row
impots <- impots[-1, ]

# Assign the text to the 1st row and 1st column
impots[1, 1] <- "Coefficient d'impôt en %"
# Replace column names with the content of the first row
colnames(impots) <- impots[1, ]
impots <- impots[-1, ]

# Check for missing values in impots
any_missing <- any(is.na(impots))

if (any_missing) {
  print("There are missing values in impots.")
} else {
  print("There are no missing values in impots.")
}


# Replace row names with the content of the 3rd column
row.names(impots) <- impots[, 3]
impots <- impots[, -3]

# Remove 2nd column (to avoid canton column)
impots <- impots[, -2]
# Remove impot eglise
impots <- impots[, -c(4:6)]
impots <- impots[, -c(6:8)]
impots <- impots[, -8]
impots <- impots[, -10]
# Clean data and convert to numeric
cleaned_impots <- apply(impots, 2, function(x) as.numeric(gsub("[^0-9.-]", "", x)))

# Replace NA values with 0
cleaned_impots[is.na(cleaned_impots)] <- 0

# Check for non-numeric values
non_numeric <- sum(!is.na(cleaned_impots) & !is.numeric(cleaned_impots))
if (non_numeric > 0) {
  print(paste("Warning: Found", non_numeric, "non-numeric values."))
}

rownames(cleaned_impots) <- rownames(impots)

reactable(head(cleaned_impots, 100),
          bordered = TRUE,
          striped = TRUE,
          highlight = TRUE,
          defaultPageSize = 5,
          showPageSizeOptions = TRUE,
          showPagination = TRUE,
          showSortable = TRUE,
          )

```

## Commune Data

### Wrangling and Cleaning

The Regional Portrait 2021 (Portraits régionaux 2021: chiffres-clés de toutes les communes) is the most recent data set provided by the Swiss Federal Statistical Office, providing key figures for all municipalities in Switzerland. We incorporate this data set in our analysis to include the external environment that may impact the prices of real estate. The completeness and precision of the data makes the cleaning task easier. The outlines of the significant steps are as follows:

-   We select only the most recent year with complete data (2019).
-   We remove the marked missing values. Either marked as "M = Not indicated because data was not important or applicable" or as "Q = Not indicated to protect confidentiality".

The data set comprising of both detailed data and aggregates:

-   We remove aggregate values to retain the most information.

We make the decision to replace the 480 missing values for the "Taux de couverture sociale" variable by the Swiss mean for 2019 (3.2%). These values were marked as missing for reason "Q = Not indicated to protect confidentiality". We are aware that this decision introduces some bias. For example, it could be hypothesized that the Federal Statistic Office had decided to remove the value from public registers above a certain percentage to protect confidentiality and avoid prejudice, therefore distorting our analysis. Nonetheless, we value the information contained in this variable, and therefore, keep it in our model.

-   Source - [Federal Statistical Office](https://www.bfs.admin.ch/bfs/fr/home/statistiques/statistique-regions/portraits-regionaux-chiffres-cles/communes.assetdetail.15864461.html)

```{r commune, warning=FALSE}
# il faudra changer le path
commune_prep <- read.csv(file.path(here(),"data/commune_data.csv"), sep = ";", header = TRUE, stringsAsFactors = FALSE)

# We keep only 2019 to have some reference? (2020 is apparently not really complete)
commune_2019 <- subset(commune_prep, PERIOD_REF == "2019") %>%
  select(c("REGION", "CODE_REGION", "INDICATORS", "VALUE", "STATUS"))

# delete les lignes ou Status = Q ou M (pas de valeur) et ensuite on enlève la colonne
commune_2019 <- subset(commune_2019, STATUS == "A") %>%
  select(c("REGION", "CODE_REGION", "INDICATORS", "VALUE"))

# on enlève les lignes qui sont des aggrégats
commune_2019 <- subset(commune_2019, REGION != "Schweiz")

commune_2019 <- commune_2019 %>%
  pivot_wider(names_from = INDICATORS, values_from = VALUE)

# Rename columns using the provided map
commune <- commune_2019 %>%
  rename(`Population - Habitants` = Ind_01_01,
         `Population - Densité de la population` = Ind_01_03,
         `Population - Etrangers` = Ind_01_08,
         `Population - Part du groupe d'âge 0-19 ans` = Ind_01_04,
         `Population - Part du groupe d'âge 20-64 ans` = Ind_01_05,
         `Population - Part du groupe d'âge 65+ ans` = Ind_01_06,
         `Population - Taux brut de nuptialité` = Ind_01_09,
         `Population - Taux brut de divortialité` = Ind_01_10,
         `Population - Taux brut de natalité` = Ind_01_11,
         `Population - Taux brut de mortalité` = Ind_01_12,
         `Population - Ménages privés` = Ind_01_13,
         `Population - Taille moyenne des ménages` = Ind_01_14,
         `Sécurité sociale - Taux d'aide sociale` = Ind_11_01,
         `Conseil national - PLR` = Ind_14_01,
         `Conseil national - PDC` = Ind_14_02,
         `Conseil national - PS` = Ind_14_03,
         `Conseil national - UDC` = Ind_14_04,
         `Conseil national - PEV/PCS` = Ind_14_05,
         `Conseil national - PVL` = Ind_14_06,
         `Conseil national - PBD` = Ind_14_07,
         `Conseil national - PST/Sol.` = Ind_14_08,
         `Conseil national - PES` = Ind_14_09,
         `Conseil national - Petits partis de droite` = Ind_14_10)

# If no one voted for a party, set as NA -> replacing it with 0 instead
commune <- commune %>%
  mutate_at(vars(starts_with("Conseil national")), ~replace_na(., 0))


# Removing NAs from Taux de couverture sociale column
# Setting the mean as the mean for Switzerland in 2019 (3.2%)
mean_taux_aide_social <- 3.2

# Replace NA values with the mean
commune <- commune %>%
  mutate(`Sécurité sociale - Taux d'aide sociale` = if_else(is.na(`Sécurité sociale - Taux d'aide sociale`), mean_taux_aide_social, `Sécurité sociale - Taux d'aide sociale`))
#show 100 first rows of commune using reactable
reactable(head(commune, 100),
          bordered = TRUE,
          striped = TRUE,
          highlight = TRUE,
          defaultPageSize = 5,
          showPageSizeOptions = TRUE,
          showPagination = TRUE,
          showSortable = TRUE,
          )
rm(amto)
rm(commune_prep)
rm(commune_2019)
rm(df)
rm(observations_table)
rm(summary_stats)
# commune_prep <- read.csv(file.path(here(),"data/commune_data.csv"), sep = ";", header = TRUE, stringsAsFactors = FALSE)
# 
# # We keep only 2019 to have some reference? (2020 is apparently not really complete)
# commune_2019 <- subset(commune_prep, PERIOD_REF == "2019") %>%
#   select(c("REGION", "CODE_REGION", "INDICATORS", "VALUE", "STATUS"))
# 
# # delete les lignes ou Status = Q ou M (pas de valeur) et ensuite on enlève la colonne
# commune_2019 <- subset(commune_2019, STATUS == "A") %>%
#   select(c("REGION", "CODE_REGION", "INDICATORS", "VALUE"))
# 
# # on enlève les lignes qui sont des aggrégats
# commune_2019 <- subset(commune_2019, REGION != "Schweiz")
# 
# commune_2019 <- commune_2019 %>%
#   pivot_wider(names_from = INDICATORS, values_from = VALUE)
# 
# # Rename columns using the provided map
# commune <- commune_2019 %>%
#   rename(`Population - Habitants` = Ind_01_01,
#          `Population - Densité de la population` = Ind_01_03,
#          `Population - Etrangers` = Ind_01_08,
#          `Population - Part du groupe d'âge 0-19 ans` = Ind_01_04,
#          `Population - Part du groupe d'âge 20-64 ans` = Ind_01_05,
#          `Population - Part du groupe d'âge 65+ ans` = Ind_01_06,
#          `Population - Taux brut de nuptialité` = Ind_01_09,
#          `Population - Taux brut de divortialité` = Ind_01_10,
#          `Population - Taux brut de natalité` = Ind_01_11,
#          `Population - Taux brut de mortalité` = Ind_01_12,
#          `Population - Ménages privés` = Ind_01_13,
#          `Population - Taille moyenne des ménages` = Ind_01_14,
#          `Sécurité sociale - Taux d'aide sociale` = Ind_11_01,
#          `Conseil national - PLR` = Ind_14_01,
#          `Conseil national - PDC` = Ind_14_02,
#          `Conseil national - PS` = Ind_14_03,
#          `Conseil national - UDC` = Ind_14_04,
#          `Conseil national - PEV/PCS` = Ind_14_05,
#          `Conseil national - PVL` = Ind_14_06,
#          `Conseil national - PBD` = Ind_14_07,
#          `Conseil national - PST/Sol.` = Ind_14_08,
#          `Conseil national - PES` = Ind_14_09,
#          `Conseil national - Petits partis de droite` = Ind_14_10)
# 
# # If no one voted for a party, set as NA -> replacing it with 0 instead
# commune <- commune %>%
#   mutate_at(vars(starts_with("Conseil national")), ~replace_na(., 0))
# 
# 
# # Removing NAs from Taux de couverture sociale column
# # Setting the mean as the mean for Switzerland in 2019 (3.2%)
# mean_taux_aide_social <- 3.2
# 
# # Replace NA values with the mean
# commune <- commune %>%
#   mutate(`Sécurité sociale - Taux d'aide sociale` = if_else(is.na(`Sécurité sociale - Taux d'aide sociale`), mean_taux_aide_social, `Sécurité sociale - Taux d'aide sociale`))
# 
```
